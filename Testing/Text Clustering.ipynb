{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# For computational efficiency, you might want to use a subset\n",
    "texts = newsgroups.data  # Use all data or limit to a subset\n",
    "\n",
    "# Step 2: Preprocess the Text (Basic preprocessing)\n",
    "# Remove headers, footers, quotes (optional)\n",
    "\n",
    "# Step 3: Feature Extraction\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Step 4: Dimensionality Reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X.toarray())\n",
    "\n",
    "# Step 5: Apply Clustering Algorithm\n",
    "num_clusters = 20  # Since we have 20 newsgroups\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Step 6: Evaluate and Visualize Clusters\n",
    "labels = kmeans.labels_\n",
    "true_labels = newsgroups.target\n",
    "\n",
    "# Evaluate clustering performance\n",
    "homogeneity = homogeneity_score(true_labels, labels)\n",
    "silhouette = silhouette_score(X, labels, sample_size=1000)\n",
    "\n",
    "print(f\"Homogeneity Score: {homogeneity}\")\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=labels, cmap='rainbow', alpha=0.5)\n",
    "plt.title('K-Means Clustering of 20 Newsgroups')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the number of clusters\n",
    "# num_clusters = 4\n",
    "\n",
    "# # Apply K-Means clustering\n",
    "# kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "# kmeans.fit(X_train_tfidf)\n",
    "\n",
    "# # Predict cluster labels for the test data\n",
    "# y_kmeans = kmeans.predict(X_test_tfidf)\n",
    "\n",
    "# # Visualizing the clusters using PCA (for 2D plotting)\n",
    "# pca = PCA(n_components=2, random_state=42)\n",
    "# X_test_pca = pca.fit_transform(X_test_tfidf.toarray())\n",
    "\n",
    "# # Plot the clusters\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_kmeans, cmap='rainbow')\n",
    "# plt.title('K-Means Clustering of 20 Newsgroups Dataset')\n",
    "# plt.xlabel('PCA Component 1')\n",
    "# plt.ylabel('PCA Component 2')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
